"""
utils/data_utils.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ç»Ÿä¸€å¤„ç† KaggleHub æ•°æ®é›†ä¸‹è½½ + Torch DataLoader åŠ è½½
æ”¯æŒæ•°æ®é›†ï¼š
    â€¢ mnist           ï¼ˆhojjatk/mnist-datasetï¼‰
    â€¢ fashion_mnist   ï¼ˆzalando-research/fashionmnistï¼‰
ä¾èµ–ï¼š
    pip install kagglehub torch torchvision tqdm
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

from pathlib import Path
from typing import Tuple
import os
import shutil
import tarfile
import zipfile

# ---------------------------------------------------------------------
# 0ï¸âƒ£ Kaggle æ•°æ®é›† slug å¯¹ç…§è¡¨
# ---------------------------------------------------------------------
KAGGLE_DATASETS = {
    "mnist": "hojjatk/mnist-dataset",
    "fashion_mnist": "zalando-research/fashionmnist",
}

# ---------------------------------------------------------------------
# ğŸ”§ å·¥å…·å‡½æ•°
# ---------------------------------------------------------------------
def _download_via_kagglehub(slug: str) -> Path:
    """è°ƒç”¨ kagglehub ä¸‹è½½å¹¶è¿”å›ç¼“å­˜ç›®å½•"""
    import kagglehub
    return Path(kagglehub.dataset_download(slug))

# â€”â€” PATCHï¼šå¿½ç•¥åªè¯»ä½å¤åˆ¶æ–‡ä»¶ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def _safe_copy(src: Path, dst: Path):
    """
    Windows ä¸‹ KaggleHub è§£å‹æ–‡ä»¶å¸¸å¸¦åªè¯»å±æ€§ï¼Œshutil.copy2 ä¼šæŠ¥
    PermissionErrorï¼›æ­¤å‡½æ•°å…ˆå»æ‰åªè¯»ä½å†å¤åˆ¶ã€‚
    """
    try:
        shutil.copy2(src, dst)
    except PermissionError:
        os.chmod(src, 0o644)         # 0o644 = å¯è¯»å†™ã€ä¸æ‰§è¡Œ
        shutil.copy2(src, dst)

def _extract_archive(archive: Path, dst: Path):
    """æ”¯æŒ .zip / .tar / .tgz è§£å‹"""
    if archive.suffix == ".zip":
        with zipfile.ZipFile(archive) as zf:
            zf.extractall(dst)
    elif archive.suffix in {".tar", ".tgz", ".gz"}:
        with tarfile.open(archive) as tf:
            tf.extractall(dst)
    else:
        raise ValueError(f"Unknown archive type: {archive}")

# ---------------------------------------------------------------------
# 1ï¸âƒ£ ä¸»å…¥å£ï¼šä¸‹è½½å¹¶æ”¾å…¥ data/raw/<dataset_name>
# ---------------------------------------------------------------------
def download_dataset(name: str, raw_root: str | Path = "data/raw") -> Path:
    """
    ä¸‹è½½æŒ‡å®šæ•°æ®é›†åˆ° data/raw/<name>/ï¼Œè‹¥å·²å­˜åœ¨åˆ™ç›´æ¥è¿”å›è·¯å¾„
    """
    if name not in KAGGLE_DATASETS:
        raise ValueError(f"Unknown dataset {name!r}. "
                         f"Choices: {list(KAGGLE_DATASETS)}")

    slug      = KAGGLE_DATASETS[name]
    cache_dir = _download_via_kagglehub(slug)

    dst_dir = Path(raw_root) / name
    dst_dir.mkdir(parents=True, exist_ok=True)

    # æŠŠç¼“å­˜ç›®å½•é‡Œçš„æ‰€æœ‰æ–‡ä»¶å¤åˆ¶æˆ–è§£å‹åˆ°ç›®æ ‡ç›®å½•
    for p in cache_dir.iterdir():
        # MNIST / Fashion-MNIST çš„å››ä¸ª .gz å·²è¢« kagglehub è§£å¼€æˆæ— æ‰©å±•åæ–‡ä»¶
        if p.is_file() and p.suffix in {".gz", ".xz", ".bz2"}:
            _safe_copy(p, dst_dir / p.name)
        elif p.is_file() and p.suffix in {".zip", ".tar", ".tgz"}:
            _extract_archive(p, dst_dir)
        elif p.is_file():
            _safe_copy(p, dst_dir / p.name)
        else:
            # è‹¥æ˜¯ç›®å½•ï¼Œæ•´ä»½å¤åˆ¶
            try:
                shutil.copytree(p, dst_dir / p.name, dirs_exist_ok=True)
            except PermissionError:
                # å¤„ç†ç›®å½•ä¸­æ–‡ä»¶çš„æƒé™é—®é¢˜
                for root, dirs, files in os.walk(p):
                    for file in files:
                        file_path = Path(root) / file
                        try:
                            os.chmod(file_path, 0o644)
                        except:
                            pass
                shutil.copytree(p, dst_dir / p.name, dirs_exist_ok=True)

    return dst_dir.resolve()

# ---------------------------------------------------------------------
# 2ï¸âƒ£ Torch DataLoader å¿«æ·å°è£…
# ---------------------------------------------------------------------
def get_dataloaders(name: str,
                    batch_size: int = 64,
                    root: str | Path = "data/raw") -> Tuple["DataLoader","DataLoader"]:
    """ä¸‹è½½ï¼ˆå¦‚éœ€è¦ï¼‰å¹¶è¿”å› train_loader, test_loader"""
    from torchvision import datasets, transforms
    from torch.utils.data import DataLoader

    root = Path(root).resolve()
    download_dataset(name, root)     # ç¡®ä¿å­˜åœ¨

    tfm = transforms.ToTensor()
    data_dir = root / name

    if name == "mnist":
        train_ds = datasets.MNIST(data_dir, train=True,  download=False, transform=tfm)
        test_ds  = datasets.MNIST(data_dir, train=False, download=False, transform=tfm)
    elif name == "fashion_mnist":
        train_ds = datasets.FashionMNIST(data_dir, train=True,  download=False, transform=tfm)
        test_ds  = datasets.FashionMNIST(data_dir, train=False, download=False, transform=tfm)
    else:
        raise ValueError(f"Unknown dataset {name}")

    return (DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=2),
            DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=2))

# ---------------------------------------------------------------------
# 3ï¸âƒ£ CLI ä½¿ç”¨ç¤ºä¾‹ï¼špython utils/data_utils.py mnist
# ---------------------------------------------------------------------
if __name__ == "__main__":
    import argparse, textwrap

    parser = argparse.ArgumentParser(
        description="Download dataset to data/raw/<name>",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=textwrap.dedent("""
            Examples:
              python utils/data_utils.py mnist
              python utils/data_utils.py fashion_mnist
        """)
    )
    parser.add_argument("name", choices=KAGGLE_DATASETS)
    args = parser.parse_args()

    print("Downloading â€¦")
    path = download_dataset(args.name)
    print("Saved to:", path)
